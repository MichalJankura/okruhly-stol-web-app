name: Run Web Scraper Every 2 Days

on:
  schedule:
    - cron: '0 0 */2 * *'  # Every 2 days at midnight UTC
  workflow_dispatch:        # Allows manual trigger

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: scraper

    steps:
      - name: ðŸ§¾ Checkout repo
        uses: actions/checkout@v3

      - name: ðŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ðŸ“¦ Install dependencies
        run: pip install -r requirements.txt

      - name: ðŸ” Set environment variables
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}  # ðŸ‘ˆ Add this in GitHub Secrets
        run: |
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV

      - name: ðŸš€ Run scraper
        run: python scrapping.py
